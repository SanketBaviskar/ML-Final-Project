{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Making predictions\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "The feature names should match those that were passed during fit.\nFeature names unseen at fit time:\n- Predicted_Weekly_Sales\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32mf:\\ML Final Project\\sup.ipynb Cell 1\u001b[0m line \u001b[0;36m1\n\u001b[0;32m    <a href='vscode-notebook-cell:/f%3A/ML%20Final%20Project/sup.ipynb#W0sZmlsZQ%3D%3D?line=116'>117</a>\u001b[0m rf_model\u001b[39m.\u001b[39mfit(X_train, y_train)\n\u001b[0;32m    <a href='vscode-notebook-cell:/f%3A/ML%20Final%20Project/sup.ipynb#W0sZmlsZQ%3D%3D?line=118'>119</a>\u001b[0m \u001b[39m# Predict and plot for Random Forest\u001b[39;00m\n\u001b[1;32m--> <a href='vscode-notebook-cell:/f%3A/ML%20Final%20Project/sup.ipynb#W0sZmlsZQ%3D%3D?line=119'>120</a>\u001b[0m PredictAndPlot(rf_model, test, \u001b[39m'\u001b[39;49m\u001b[39mRandom Forest\u001b[39;49m\u001b[39m'\u001b[39;49m)\n\u001b[0;32m    <a href='vscode-notebook-cell:/f%3A/ML%20Final%20Project/sup.ipynb#W0sZmlsZQ%3D%3D?line=121'>122</a>\u001b[0m \u001b[39m# Train XGBoost model\u001b[39;00m\n\u001b[0;32m    <a href='vscode-notebook-cell:/f%3A/ML%20Final%20Project/sup.ipynb#W0sZmlsZQ%3D%3D?line=122'>123</a>\u001b[0m xgb_model \u001b[39m=\u001b[39m XGBRegressor(n_estimators\u001b[39m=\u001b[39m\u001b[39m100\u001b[39m, random_state\u001b[39m=\u001b[39m\u001b[39m42\u001b[39m)\n",
      "\u001b[1;32mf:\\ML Final Project\\sup.ipynb Cell 1\u001b[0m line \u001b[0;36m9\n\u001b[0;32m     <a href='vscode-notebook-cell:/f%3A/ML%20Final%20Project/sup.ipynb#W0sZmlsZQ%3D%3D?line=87'>88</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mPredictAndPlot\u001b[39m(model, X_test, model_name):\n\u001b[0;32m     <a href='vscode-notebook-cell:/f%3A/ML%20Final%20Project/sup.ipynb#W0sZmlsZQ%3D%3D?line=88'>89</a>\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mMaking predictions\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m---> <a href='vscode-notebook-cell:/f%3A/ML%20Final%20Project/sup.ipynb#W0sZmlsZQ%3D%3D?line=89'>90</a>\u001b[0m     preds \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39;49mpredict(X_test)\n\u001b[0;32m     <a href='vscode-notebook-cell:/f%3A/ML%20Final%20Project/sup.ipynb#W0sZmlsZQ%3D%3D?line=92'>93</a>\u001b[0m     \u001b[39m# Create a DataFrame with test predictions\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/f%3A/ML%20Final%20Project/sup.ipynb#W0sZmlsZQ%3D%3D?line=93'>94</a>\u001b[0m     predictions_df \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mDataFrame({\n\u001b[0;32m     <a href='vscode-notebook-cell:/f%3A/ML%20Final%20Project/sup.ipynb#W0sZmlsZQ%3D%3D?line=94'>95</a>\u001b[0m         \u001b[39m'\u001b[39m\u001b[39mDate\u001b[39m\u001b[39m'\u001b[39m: test\u001b[39m.\u001b[39mindex,\n\u001b[0;32m     <a href='vscode-notebook-cell:/f%3A/ML%20Final%20Project/sup.ipynb#W0sZmlsZQ%3D%3D?line=95'>96</a>\u001b[0m         \u001b[39m'\u001b[39m\u001b[39mPredicted_Weekly_Sales\u001b[39m\u001b[39m'\u001b[39m: preds\n\u001b[0;32m     <a href='vscode-notebook-cell:/f%3A/ML%20Final%20Project/sup.ipynb#W0sZmlsZQ%3D%3D?line=96'>97</a>\u001b[0m     })\n",
      "File \u001b[1;32mc:\\Users\\sanke\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\ensemble\\_forest.py:984\u001b[0m, in \u001b[0;36mForestRegressor.predict\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    982\u001b[0m check_is_fitted(\u001b[39mself\u001b[39m)\n\u001b[0;32m    983\u001b[0m \u001b[39m# Check data\u001b[39;00m\n\u001b[1;32m--> 984\u001b[0m X \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_validate_X_predict(X)\n\u001b[0;32m    986\u001b[0m \u001b[39m# Assign chunk of trees to jobs\u001b[39;00m\n\u001b[0;32m    987\u001b[0m n_jobs, _, _ \u001b[39m=\u001b[39m _partition_estimators(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_estimators, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_jobs)\n",
      "File \u001b[1;32mc:\\Users\\sanke\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\ensemble\\_forest.py:599\u001b[0m, in \u001b[0;36mBaseForest._validate_X_predict\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    596\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    597\u001b[0m \u001b[39mValidate X whenever one tries to predict, apply, predict_proba.\"\"\"\u001b[39;00m\n\u001b[0;32m    598\u001b[0m check_is_fitted(\u001b[39mself\u001b[39m)\n\u001b[1;32m--> 599\u001b[0m X \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_validate_data(X, dtype\u001b[39m=\u001b[39;49mDTYPE, accept_sparse\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mcsr\u001b[39;49m\u001b[39m\"\u001b[39;49m, reset\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m)\n\u001b[0;32m    600\u001b[0m \u001b[39mif\u001b[39;00m issparse(X) \u001b[39mand\u001b[39;00m (X\u001b[39m.\u001b[39mindices\u001b[39m.\u001b[39mdtype \u001b[39m!=\u001b[39m np\u001b[39m.\u001b[39mintc \u001b[39mor\u001b[39;00m X\u001b[39m.\u001b[39mindptr\u001b[39m.\u001b[39mdtype \u001b[39m!=\u001b[39m np\u001b[39m.\u001b[39mintc):\n\u001b[0;32m    601\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mNo support for np.int64 index based sparse matrices\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\sanke\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\base.py:580\u001b[0m, in \u001b[0;36mBaseEstimator._validate_data\u001b[1;34m(self, X, y, reset, validate_separately, cast_to_ndarray, **check_params)\u001b[0m\n\u001b[0;32m    509\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_validate_data\u001b[39m(\n\u001b[0;32m    510\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[0;32m    511\u001b[0m     X\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mno_validation\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    516\u001b[0m     \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mcheck_params,\n\u001b[0;32m    517\u001b[0m ):\n\u001b[0;32m    518\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Validate input data and set or check the `n_features_in_` attribute.\u001b[39;00m\n\u001b[0;32m    519\u001b[0m \n\u001b[0;32m    520\u001b[0m \u001b[39m    Parameters\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    578\u001b[0m \u001b[39m        validated.\u001b[39;00m\n\u001b[0;32m    579\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 580\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_check_feature_names(X, reset\u001b[39m=\u001b[39;49mreset)\n\u001b[0;32m    582\u001b[0m     \u001b[39mif\u001b[39;00m y \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_get_tags()[\u001b[39m\"\u001b[39m\u001b[39mrequires_y\u001b[39m\u001b[39m\"\u001b[39m]:\n\u001b[0;32m    583\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m    584\u001b[0m             \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mThis \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__class__\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m estimator \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    585\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mrequires y to be passed, but the target y is None.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    586\u001b[0m         )\n",
      "File \u001b[1;32mc:\\Users\\sanke\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\base.py:507\u001b[0m, in \u001b[0;36mBaseEstimator._check_feature_names\u001b[1;34m(self, X, reset)\u001b[0m\n\u001b[0;32m    502\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m missing_names \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m unexpected_names:\n\u001b[0;32m    503\u001b[0m     message \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m (\n\u001b[0;32m    504\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mFeature names must be in the same order as they were in fit.\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[0;32m    505\u001b[0m     )\n\u001b[1;32m--> 507\u001b[0m \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(message)\n",
      "\u001b[1;31mValueError\u001b[0m: The feature names should match those that were passed during fit.\nFeature names unseen at fit time:\n- Predicted_Weekly_Sales\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import statsmodels.api as sm\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "\n",
    "\n",
    "#Read the input files\n",
    "train = pd.read_csv('train.csv')\n",
    "test = pd.read_csv('test.csv')\n",
    "store = pd.read_csv('stores.csv')\n",
    "feature = pd.read_csv('features.csv')\n",
    "\n",
    "\n",
    "train['Date'] = pd.to_datetime(train['Date'])\n",
    "test['Date'] = pd.to_datetime(test['Date'])\n",
    "feature['Date']=pd.to_datetime(feature['Date'])\n",
    "\n",
    "# Splitting month, year and day - train\n",
    "train['Month']=train['Date'].dt.month\n",
    "train['Year']=train['Date'].dt.year\n",
    "train['Dayofweek']=train['Date'].dt.dayofweek\n",
    "\n",
    "# Splitting month, year and day - test\n",
    "test['Month']=test['Date'].dt.month\n",
    "test['Year']=test['Date'].dt.year\n",
    "test['Dayofweek']=test['Date'].dt.dayofweek\n",
    "\n",
    "# set the dates as the index of the dataframe, so that it can be treated as a time-series dataframe\n",
    "train.set_index('Date',inplace=True)\n",
    "test.set_index('Date',inplace=True)\n",
    "\n",
    "#Merge train and feature\n",
    "merge_df=pd.merge(train,feature, on=['Store','Date','IsHoliday'], how='inner')\n",
    "merge_df = pd.merge(merge_df, store, on='Store', how='inner')\n",
    "\n",
    "def CompareModels(data):\n",
    "    features = ['Store', 'Dept', 'IsHoliday', 'Temperature', 'Fuel_Price', 'CPI', 'Unemployment']\n",
    "\n",
    "    train_set=data[features + ['Weekly_Sales']]\n",
    "    X_train, X_test, y_train, y_test = train_test_split(train_set[features], train_set['Weekly_Sales'], test_size=0.2,\n",
    "                                                        random_state=42)\n",
    "    # Random Forest\n",
    "    rf_model = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "    rf_model.fit(X_train, y_train)\n",
    "\n",
    "    # XGBoost\n",
    "    xgb_model = XGBRegressor(n_estimators=100, random_state=42)\n",
    "    xgb_model.fit(X_train, y_train)\n",
    "\n",
    "    # Making predictions\n",
    "    rf_preds = rf_model.predict(X_test)\n",
    "    mae = mean_absolute_error(y_test, rf_preds)\n",
    "    print(\"Random Forest - MAE :\"+str(mae))\n",
    "    rmse = np.sqrt(mean_squared_error(y_test, rf_preds))\n",
    "    print(\"Random Forest - RMSE :\"+str(rmse))\n",
    "    accuracy = 1 - mae / np.mean(y_test)\n",
    "    print(\"Random Forest - Accuracy : \"+str(+accuracy*100)+\"%\")\n",
    "\n",
    "    xgb_preds = xgb_model.predict(X_test)\n",
    "    mae = mean_absolute_error(y_test, xgb_preds)\n",
    "    print(\"XGBoost - MAE :\" + str(mae))\n",
    "    rmse = np.sqrt(mean_squared_error(y_test, xgb_preds))\n",
    "    print(\"XGBoost - RMSE :\" + str(rmse))\n",
    "    accuracy = 1 - mae / np.mean(y_test)\n",
    "    print(\"XGBoost - Accuracy : \" + str(accuracy*100)+\"%\")\n",
    "    # Plotting results\n",
    "    plt.figure(figsize=(14, 7))\n",
    "\n",
    "    plt.plot(y_test.index, y_test.values, label='Actual Sales', color='black')\n",
    "    plt.plot(y_test.index, rf_preds, label='Random Forest Predictions', color='blue')\n",
    "    plt.plot(y_test.index, xgb_preds, label='XG Boost Predictions', color='red')\n",
    "\n",
    "    plt.xlabel('Date')\n",
    "    plt.ylabel('Weekly Sales')\n",
    "    plt.title(f'Sales Prediction Comparison')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "#print(\"Comparing models\")\n",
    "\n",
    "#CompareModels(merge_df)\n",
    "\n",
    "def PredictAndPlot(model, X_test, model_name):\n",
    "    print(\"Making predictions\")\n",
    "    preds = model.predict(X_test)\n",
    "\n",
    "\n",
    "    # Create a DataFrame with test predictions\n",
    "    predictions_df = pd.DataFrame({\n",
    "        'Date': test.index,\n",
    "        'Predicted_Weekly_Sales': preds\n",
    "    })\n",
    "\n",
    "    # Aggregate predictions by taking the mean for each week\n",
    "    aggregated_predictions = predictions_df.groupby('Date').mean()\n",
    "    # Plotting results\n",
    "    plt.figure(figsize=(14, 7))\n",
    "    plt.plot(aggregated_predictions.index, aggregated_predictions['Predicted_Weekly_Sales'], label='Predictions',\n",
    "             color='blue')\n",
    "    plt.xlabel('Date')\n",
    "    plt.ylabel('Weekly Sales')\n",
    "    plt.title(f'{model_name} - Sales Prediction')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "y_train=train[\"Weekly_Sales\"]\n",
    "X_train=train.drop(\"Weekly_Sales\", axis=1)\n",
    "\n",
    "# Train Random Forest model\n",
    "rf_model = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "rf_model.fit(X_train, y_train)\n",
    "\n",
    "# Predict and plot for Random Forest\n",
    "PredictAndPlot(rf_model, test, 'Random Forest')\n",
    "\n",
    "# Train XGBoost model\n",
    "xgb_model = XGBRegressor(n_estimators=100, random_state=42)\n",
    "xgb_model.fit(X_train, y_train)\n",
    "\n",
    "# Predict and plot for XGBoost\n",
    "PredictAndPlot(xgb_model, test, 'XGBoost')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
