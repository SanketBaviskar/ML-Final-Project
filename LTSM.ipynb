{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM, Dense, Dropout\n",
    "\n",
    "# Load data\n",
    "stores = pd.read_csv('stores.csv')\n",
    "train = pd.read_csv('train.csv')\n",
    "features = pd.read_csv('features.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge datasets\n",
    "data = pd.merge(train, stores, how='left', on='Store')\n",
    "data = pd.merge(data, features, how='left', on=['Store', 'Date'])\n",
    "\n",
    "# Data preprocessing\n",
    "data['Date'] = pd.to_datetime(data['Date'])\n",
    "data = data.sort_values(by='Date')\n",
    "data = data.fillna(0)  # Fill missing values with 0 for simplicity\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature engineering\n",
    "# Add lag features for weekly sales\n",
    "data['Lag_1_Weekly_Sales'] = data.groupby(['Store', 'Dept'])['Weekly_Sales'].shift(1)\n",
    "data['Lag_2_Weekly_Sales'] = data.groupby(['Store', 'Dept'])['Weekly_Sales'].shift(2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalization\n",
    "scaler = MinMaxScaler()\n",
    "data[['Weekly_Sales', 'Lag_1_Weekly_Sales', 'Lag_2_Weekly_Sales', 'Temperature', 'Fuel_Price',\n",
    "      'MarkDown1', 'MarkDown2', 'MarkDown3', 'MarkDown4', 'MarkDown5', 'CPI', 'Unemployment']] = \\\n",
    "    scaler.fit_transform(data[['Weekly_Sales', 'Lag_1_Weekly_Sales', 'Lag_2_Weekly_Sales',\n",
    "                               'Temperature', 'Fuel_Price', 'MarkDown1', 'MarkDown2', 'MarkDown3',\n",
    "                               'MarkDown4', 'MarkDown5', 'CPI', 'Unemployment']])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sequence preparation\n",
    "X = data[['Lag_1_Weekly_Sales', 'Lag_2_Weekly_Sales', 'Temperature', 'Fuel_Price',\n",
    "           'MarkDown1', 'MarkDown2', 'MarkDown3', 'MarkDown4', 'MarkDown5', 'CPI', 'Unemployment']].values\n",
    "y = data['Weekly_Sales'].values\n",
    "\n",
    "X = X.reshape(X.shape[0], 1, X.shape[1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split into training and validation sets\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Build LSTM model\n",
    "model = Sequential()\n",
    "model.add(LSTM(units=50, return_sequences=True, input_shape=(X_train.shape[1], X_train.shape[2])))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(LSTM(units=50, return_sequences=True))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(LSTM(units=50))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(units=1))\n",
    "model.compile(optimizer='adam', loss='mean_squared_error')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "10540/10540 [==============================] - 36s 3ms/step - loss: nan - val_loss: nan\n",
      "Epoch 2/50\n",
      "10540/10540 [==============================] - 33s 3ms/step - loss: nan - val_loss: nan\n",
      "Epoch 3/50\n",
      "10540/10540 [==============================] - 32s 3ms/step - loss: nan - val_loss: nan\n",
      "Epoch 4/50\n",
      "10540/10540 [==============================] - 32s 3ms/step - loss: nan - val_loss: nan\n",
      "Epoch 5/50\n",
      "10540/10540 [==============================] - 32s 3ms/step - loss: nan - val_loss: nan\n",
      "Epoch 6/50\n",
      "10540/10540 [==============================] - 32s 3ms/step - loss: nan - val_loss: nan\n",
      "Epoch 7/50\n",
      "10540/10540 [==============================] - 32s 3ms/step - loss: nan - val_loss: nan\n",
      "Epoch 8/50\n",
      "10540/10540 [==============================] - 32s 3ms/step - loss: nan - val_loss: nan\n",
      "Epoch 9/50\n",
      "10540/10540 [==============================] - 34s 3ms/step - loss: nan - val_loss: nan\n",
      "Epoch 10/50\n",
      "10540/10540 [==============================] - 33s 3ms/step - loss: nan - val_loss: nan\n",
      "Epoch 11/50\n",
      "10540/10540 [==============================] - 31s 3ms/step - loss: nan - val_loss: nan\n",
      "Epoch 12/50\n",
      "10540/10540 [==============================] - 33s 3ms/step - loss: nan - val_loss: nan\n",
      "Epoch 13/50\n",
      "10540/10540 [==============================] - 33s 3ms/step - loss: nan - val_loss: nan\n",
      "Epoch 14/50\n",
      "10540/10540 [==============================] - 37s 4ms/step - loss: nan - val_loss: nan\n",
      "Epoch 15/50\n",
      "10540/10540 [==============================] - 35s 3ms/step - loss: nan - val_loss: nan\n",
      "Epoch 16/50\n",
      "10540/10540 [==============================] - 36s 3ms/step - loss: nan - val_loss: nan\n",
      "Epoch 17/50\n",
      "10540/10540 [==============================] - 33s 3ms/step - loss: nan - val_loss: nan\n",
      "Epoch 18/50\n",
      "10540/10540 [==============================] - 32s 3ms/step - loss: nan - val_loss: nan\n",
      "Epoch 19/50\n",
      "10540/10540 [==============================] - 33s 3ms/step - loss: nan - val_loss: nan\n",
      "Epoch 20/50\n",
      "10540/10540 [==============================] - 34s 3ms/step - loss: nan - val_loss: nan\n",
      "Epoch 21/50\n",
      "10540/10540 [==============================] - 34s 3ms/step - loss: nan - val_loss: nan\n",
      "Epoch 22/50\n",
      "10540/10540 [==============================] - 35s 3ms/step - loss: nan - val_loss: nan\n",
      "Epoch 23/50\n",
      "10540/10540 [==============================] - 35s 3ms/step - loss: nan - val_loss: nan\n",
      "Epoch 24/50\n",
      "10540/10540 [==============================] - 34s 3ms/step - loss: nan - val_loss: nan\n",
      "Epoch 25/50\n",
      "10540/10540 [==============================] - 41s 4ms/step - loss: nan - val_loss: nan\n",
      "Epoch 26/50\n",
      "10540/10540 [==============================] - 38s 4ms/step - loss: nan - val_loss: nan\n",
      "Epoch 27/50\n",
      "10540/10540 [==============================] - 40s 4ms/step - loss: nan - val_loss: nan\n",
      "Epoch 28/50\n",
      "10540/10540 [==============================] - 40s 4ms/step - loss: nan - val_loss: nan\n",
      "Epoch 29/50\n",
      "10540/10540 [==============================] - 38s 4ms/step - loss: nan - val_loss: nan\n",
      "Epoch 30/50\n",
      "10540/10540 [==============================] - 37s 4ms/step - loss: nan - val_loss: nan\n",
      "Epoch 31/50\n",
      "10540/10540 [==============================] - 42s 4ms/step - loss: nan - val_loss: nan\n",
      "Epoch 32/50\n",
      "10540/10540 [==============================] - 37s 4ms/step - loss: nan - val_loss: nan\n",
      "Epoch 33/50\n",
      "10540/10540 [==============================] - 36s 3ms/step - loss: nan - val_loss: nan\n",
      "Epoch 34/50\n",
      "10540/10540 [==============================] - 36s 3ms/step - loss: nan - val_loss: nan\n",
      "Epoch 35/50\n",
      "10540/10540 [==============================] - 36s 3ms/step - loss: nan - val_loss: nan\n",
      "Epoch 36/50\n",
      "10540/10540 [==============================] - 36s 3ms/step - loss: nan - val_loss: nan\n",
      "Epoch 37/50\n",
      "10540/10540 [==============================] - 37s 3ms/step - loss: nan - val_loss: nan\n",
      "Epoch 38/50\n",
      "10540/10540 [==============================] - 37s 4ms/step - loss: nan - val_loss: nan\n",
      "Epoch 39/50\n",
      "10540/10540 [==============================] - 37s 3ms/step - loss: nan - val_loss: nan\n",
      "Epoch 40/50\n",
      "10540/10540 [==============================] - 36s 3ms/step - loss: nan - val_loss: nan\n",
      "Epoch 41/50\n",
      "10540/10540 [==============================] - 36s 3ms/step - loss: nan - val_loss: nan\n",
      "Epoch 42/50\n",
      "10540/10540 [==============================] - 36s 3ms/step - loss: nan - val_loss: nan\n",
      "Epoch 43/50\n",
      "10540/10540 [==============================] - 36s 3ms/step - loss: nan - val_loss: nan\n",
      "Epoch 44/50\n",
      "10540/10540 [==============================] - 36s 3ms/step - loss: nan - val_loss: nan\n",
      "Epoch 45/50\n",
      "10540/10540 [==============================] - 36s 3ms/step - loss: nan - val_loss: nan\n",
      "Epoch 46/50\n",
      "10540/10540 [==============================] - 36s 3ms/step - loss: nan - val_loss: nan\n",
      "Epoch 47/50\n",
      "10540/10540 [==============================] - 37s 4ms/step - loss: nan - val_loss: nan\n",
      "Epoch 48/50\n",
      "10540/10540 [==============================] - 39s 4ms/step - loss: nan - val_loss: nan\n",
      "Epoch 49/50\n",
      "10540/10540 [==============================] - 39s 4ms/step - loss: nan - val_loss: nan\n",
      "Epoch 50/50\n",
      "10540/10540 [==============================] - 37s 4ms/step - loss: nan - val_loss: nan\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x29cdc9edb10>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train the model\n",
    "model.fit(X_train, y_train, epochs=50, batch_size=32, validation_data=(X_val, y_val))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'Column not found: Weekly_Sales'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32mf:\\ML Final Project\\ltsm.ipynb Cell 8\u001b[0m line \u001b[0;36m1\n\u001b[0;32m      <a href='vscode-notebook-cell:/f%3A/ML%20Final%20Project/ltsm.ipynb#X12sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m test_data \u001b[39m=\u001b[39m test_data\u001b[39m.\u001b[39msort_values(by\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mDate\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m     <a href='vscode-notebook-cell:/f%3A/ML%20Final%20Project/ltsm.ipynb#X12sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m test_data \u001b[39m=\u001b[39m test_data\u001b[39m.\u001b[39mfillna(\u001b[39m0\u001b[39m)\n\u001b[1;32m---> <a href='vscode-notebook-cell:/f%3A/ML%20Final%20Project/ltsm.ipynb#X12sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m test_data[\u001b[39m'\u001b[39m\u001b[39mLag_1_Weekly_Sales\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m test_data\u001b[39m.\u001b[39;49mgroupby([\u001b[39m'\u001b[39;49m\u001b[39mStore\u001b[39;49m\u001b[39m'\u001b[39;49m, \u001b[39m'\u001b[39;49m\u001b[39mDept\u001b[39;49m\u001b[39m'\u001b[39;49m])[\u001b[39m'\u001b[39;49m\u001b[39mWeekly_Sales\u001b[39;49m\u001b[39m'\u001b[39;49m]\u001b[39m.\u001b[39mshift(\u001b[39m1\u001b[39m)\n\u001b[0;32m     <a href='vscode-notebook-cell:/f%3A/ML%20Final%20Project/ltsm.ipynb#X12sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m test_data[\u001b[39m'\u001b[39m\u001b[39mLag_2_Weekly_Sales\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m test_data\u001b[39m.\u001b[39mgroupby([\u001b[39m'\u001b[39m\u001b[39mStore\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mDept\u001b[39m\u001b[39m'\u001b[39m])[\u001b[39m'\u001b[39m\u001b[39mWeekly_Sales\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m.\u001b[39mshift(\u001b[39m2\u001b[39m)\n\u001b[0;32m     <a href='vscode-notebook-cell:/f%3A/ML%20Final%20Project/ltsm.ipynb#X12sZmlsZQ%3D%3D?line=14'>15</a>\u001b[0m test_data[[\u001b[39m'\u001b[39m\u001b[39mLag_1_Weekly_Sales\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mLag_2_Weekly_Sales\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mTemperature\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mFuel_Price\u001b[39m\u001b[39m'\u001b[39m,\n\u001b[0;32m     <a href='vscode-notebook-cell:/f%3A/ML%20Final%20Project/ltsm.ipynb#X12sZmlsZQ%3D%3D?line=15'>16</a>\u001b[0m            \u001b[39m'\u001b[39m\u001b[39mMarkDown1\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mMarkDown2\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mMarkDown3\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mMarkDown4\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mMarkDown5\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mCPI\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mUnemployment\u001b[39m\u001b[39m'\u001b[39m]] \u001b[39m=\u001b[39m \\\n\u001b[0;32m     <a href='vscode-notebook-cell:/f%3A/ML%20Final%20Project/ltsm.ipynb#X12sZmlsZQ%3D%3D?line=16'>17</a>\u001b[0m     scaler\u001b[39m.\u001b[39mtransform(test_data[[\u001b[39m'\u001b[39m\u001b[39mWeekly_Sales\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mLag_1_Weekly_Sales\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mLag_2_Weekly_Sales\u001b[39m\u001b[39m'\u001b[39m,\n\u001b[0;32m     <a href='vscode-notebook-cell:/f%3A/ML%20Final%20Project/ltsm.ipynb#X12sZmlsZQ%3D%3D?line=17'>18</a>\u001b[0m                                 \u001b[39m'\u001b[39m\u001b[39mTemperature\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mFuel_Price\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mMarkDown1\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mMarkDown2\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mMarkDown3\u001b[39m\u001b[39m'\u001b[39m,\n\u001b[0;32m     <a href='vscode-notebook-cell:/f%3A/ML%20Final%20Project/ltsm.ipynb#X12sZmlsZQ%3D%3D?line=18'>19</a>\u001b[0m                                 \u001b[39m'\u001b[39m\u001b[39mMarkDown4\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mMarkDown5\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mCPI\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mUnemployment\u001b[39m\u001b[39m'\u001b[39m]])\n",
      "File \u001b[1;32mc:\\Users\\sanke\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\groupby\\generic.py:1961\u001b[0m, in \u001b[0;36mDataFrameGroupBy.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   1954\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(key, \u001b[39mtuple\u001b[39m) \u001b[39mand\u001b[39;00m \u001b[39mlen\u001b[39m(key) \u001b[39m>\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[0;32m   1955\u001b[0m     \u001b[39m# if len == 1, then it becomes a SeriesGroupBy and this is actually\u001b[39;00m\n\u001b[0;32m   1956\u001b[0m     \u001b[39m# valid syntax, so don't raise\u001b[39;00m\n\u001b[0;32m   1957\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m   1958\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mCannot subset columns with a tuple with more than one element. \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   1959\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mUse a list instead.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   1960\u001b[0m     )\n\u001b[1;32m-> 1961\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49m\u001b[39m__getitem__\u001b[39;49m(key)\n",
      "File \u001b[1;32mc:\\Users\\sanke\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\base.py:244\u001b[0m, in \u001b[0;36mSelectionMixin.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m    242\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    243\u001b[0m     \u001b[39mif\u001b[39;00m key \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mobj:\n\u001b[1;32m--> 244\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mKeyError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mColumn not found: \u001b[39m\u001b[39m{\u001b[39;00mkey\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[0;32m    245\u001b[0m     ndim \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mobj[key]\u001b[39m.\u001b[39mndim\n\u001b[0;32m    246\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_gotitem(key, ndim\u001b[39m=\u001b[39mndim)\n",
      "\u001b[1;31mKeyError\u001b[0m: 'Column not found: Weekly_Sales'"
     ]
    }
   ],
   "source": [
    "# ... (previous code)\n",
    "\n",
    "# Load the test data\n",
    "test_data = pd.read_csv('test.csv')\n",
    "# Make predictions on the test dataset\n",
    "test_data = pd.merge(test_data, stores, how='left', on='Store')\n",
    "test_data = pd.merge(test_data, features, how='left', on=['Store', 'Date'])\n",
    "test_data['Date'] = pd.to_datetime(test_data['Date'])\n",
    "test_data = test_data.sort_values(by='Date')\n",
    "test_data = test_data.fillna(0)\n",
    "\n",
    "test_data['Lag_1_Weekly_Sales'] = test_data.groupby(['Store', 'Dept'])['Weekly_Sales'].shift(1)\n",
    "test_data['Lag_2_Weekly_Sales'] = test_data.groupby(['Store', 'Dept'])['Weekly_Sales'].shift(2)\n",
    "\n",
    "test_data[['Lag_1_Weekly_Sales', 'Lag_2_Weekly_Sales', 'Temperature', 'Fuel_Price',\n",
    "           'MarkDown1', 'MarkDown2', 'MarkDown3', 'MarkDown4', 'MarkDown5', 'CPI', 'Unemployment']] = \\\n",
    "    scaler.transform(test_data[['Weekly_Sales', 'Lag_1_Weekly_Sales', 'Lag_2_Weekly_Sales',\n",
    "                                'Temperature', 'Fuel_Price', 'MarkDown1', 'MarkDown2', 'MarkDown3',\n",
    "                                'MarkDown4', 'MarkDown5', 'CPI', 'Unemployment']])\n",
    "\n",
    "X_test = test_data[['Lag_1_Weekly_Sales', 'Lag_2_Weekly_Sales', 'Temperature', 'Fuel_Price',\n",
    "                    'MarkDown1', 'MarkDown2', 'MarkDown3', 'MarkDown4', 'MarkDown5', 'CPI', 'Unemployment']].values.reshape(\n",
    "    test_data.shape[0], 1, 11\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3596/3596 [==============================] - 7s 2ms/step\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "operands could not be broadcast together with shapes (115064,2) (11,) (115064,2) ",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32mf:\\ML Final Project\\ltsm.ipynb Cell 9\u001b[0m line \u001b[0;36m1\n\u001b[0;32m      <a href='vscode-notebook-cell:/f%3A/ML%20Final%20Project/ltsm.ipynb#X13sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m predictions \u001b[39m=\u001b[39m predictions\u001b[39m.\u001b[39mreshape(\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m, \u001b[39m1\u001b[39m)\n\u001b[0;32m      <a href='vscode-notebook-cell:/f%3A/ML%20Final%20Project/ltsm.ipynb#X13sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m \u001b[39m# Add the predictions back to the test_data dataframe\u001b[39;00m\n\u001b[1;32m---> <a href='vscode-notebook-cell:/f%3A/ML%20Final%20Project/ltsm.ipynb#X13sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m test_data[\u001b[39m'\u001b[39m\u001b[39mPredicted_Weekly_Sales\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m scaler\u001b[39m.\u001b[39;49minverse_transform(np\u001b[39m.\u001b[39;49mhstack([predictions, np\u001b[39m.\u001b[39;49mzeros_like(predictions)]))[:, \u001b[39m0\u001b[39m]\n\u001b[0;32m     <a href='vscode-notebook-cell:/f%3A/ML%20Final%20Project/ltsm.ipynb#X13sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m \u001b[39m# Display the predictions\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/f%3A/ML%20Final%20Project/ltsm.ipynb#X13sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m \u001b[39mprint\u001b[39m(test_data[[\u001b[39m'\u001b[39m\u001b[39mStore\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mDept\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mDate\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mPredicted_Weekly_Sales\u001b[39m\u001b[39m'\u001b[39m]])\n",
      "File \u001b[1;32mc:\\Users\\sanke\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\preprocessing\\_data.py:548\u001b[0m, in \u001b[0;36mMinMaxScaler.inverse_transform\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    542\u001b[0m check_is_fitted(\u001b[39mself\u001b[39m)\n\u001b[0;32m    544\u001b[0m X \u001b[39m=\u001b[39m check_array(\n\u001b[0;32m    545\u001b[0m     X, copy\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcopy, dtype\u001b[39m=\u001b[39mFLOAT_DTYPES, force_all_finite\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mallow-nan\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    546\u001b[0m )\n\u001b[1;32m--> 548\u001b[0m X \u001b[39m-\u001b[39;49m\u001b[39m=\u001b[39;49m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmin_\n\u001b[0;32m    549\u001b[0m X \u001b[39m/\u001b[39m\u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mscale_\n\u001b[0;32m    550\u001b[0m \u001b[39mreturn\u001b[39;00m X\n",
      "\u001b[1;31mValueError\u001b[0m: operands could not be broadcast together with shapes (115064,2) (11,) (115064,2) "
     ]
    }
   ],
   "source": [
    "predictions = model.predict(X_test)\n",
    "\n",
    "# Reshape predictions and apply inverse_transform\n",
    "predictions = predictions.reshape(-1, 1)\n",
    "test_data['Predicted_Weekly_Sales'] = scaler.inverse_transform(np.hstack([predictions, np.zeros_like(predictions)]))[:, 0]\n",
    "\n",
    "# Display the predictions\n",
    "print(test_data[['Store', 'Dept', 'Date', 'Predicted_Weekly_Sales']])\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
